{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "# Capstone\n",
    "# Project: To find an Optimum Machine Learning Model for Human Activity        Recognition with Smartphone Sensor Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Capstone for MLND.\n",
    "Our purpose is to recognize human activity based on the sensor data from smartphones and to find an optimum model with can predict these activities with high degree of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the Necessary Libraries\n",
    "\n",
    "import time, pickle\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
    "\n",
    "# Use pickle to open stored objects.\n",
    "with open('data.pickle','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "with open('X_train.pickle','rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "with open('X_test.pickle','rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "with open('y_train.pickle','rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open('y_test.pickle','rb') as f:\n",
    "    y_test = pickle.load(f)\n",
    "with open('y_true.pickle','rb') as f:\n",
    "    y_true = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier:\n",
    "\n",
    "Now we will use a Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankur/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Accuracy Score for Logistic Regression is: 0.981877022654\n",
      "F1 Score for Logistic Regression is: 0.981834941184\n",
      "Runtime is 6.154393 seconds\n",
      "Log Loss Score is: 0.0623213805757\n"
     ]
    }
   ],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_lr= LogisticRegression(solver= 'liblinear', multi_class='ovr', verbose=22, n_jobs= -1)\n",
    "start = time.clock()\n",
    "clf_lr.fit(X_train, y_train)\n",
    "pred_lr = clf_lr.predict(X_test)\n",
    "end = time.clock()\n",
    "y_pred = clf_lr.predict_proba(X_test)\n",
    "print('Accuracy Score for Logistic Regression is: {}'.format(accuracy_score(y_test, pred_lr)))\n",
    "print('F1 Score for Logistic Regression is: {}'.format(f1_score(y_test, pred_lr, average = 'weighted')))\n",
    "print('Runtime is {} seconds'.format(end-start))\n",
    "print('Log Loss Score is: {}'.format(log_loss(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Optimization:\n",
    "\n",
    "Now let us apply GridSearch to optimize the solver followed by C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of  84 | elapsed: 18.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The best classifier is: ', LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=21, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False))\n",
      "('The best score is: ', 0.98141212373422115)\n"
     ]
    }
   ],
   "source": [
    "# optimize the solver and C\n",
    "clf_lr= LogisticRegression(random_state = 21)\n",
    "parameters = {'solver' : ['liblinear', 'sag', 'newton-cg', 'lbfgs'],\n",
    "              'C':[0.001, 0.01, 1, 10, 100, 200, 500]}\n",
    "grid = GridSearchCV(clf_lr, parameters, scoring = 'accuracy', n_jobs = -1, verbose=True)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"The best classifier is: \", grid.best_estimator_)\n",
    "print(\"The best score is: \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above Grid Search, we get solver='newton-cg' and C = 100 as our best choice.\n",
    "Let us tune C again in a range of 60 to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed: 12.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The best classifier is: ', LogisticRegression(C=60, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=21, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False))\n",
      "('The best score is: ', 0.98168955472326258)\n"
     ]
    }
   ],
   "source": [
    "# optimize the C.\n",
    "clf_lr= LogisticRegression(random_state = 21)\n",
    "parameters = {'solver' : ['newton-cg'],\n",
    "              'C':[i*10 for i in range(6, 15)]}\n",
    "grid = GridSearchCV(clf_lr, parameters, scoring = 'accuracy', n_jobs = -1, verbose=True)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"The best classifier is: \", grid.best_estimator_)\n",
    "print(\"The best score is: \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The best classifier is: ', LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=21, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False))\n",
      "('The best score is: ', 0.98210570120682483)\n"
     ]
    }
   ],
   "source": [
    "# optimize the C.\n",
    "clf_lr= LogisticRegression(random_state = 21)\n",
    "parameters = {'solver' : ['newton-cg'],\n",
    "              'C':[i*10 for i in range(1, 7)]}\n",
    "grid = GridSearchCV(clf_lr, parameters, scoring = 'accuracy', n_jobs = -1, verbose=True)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"The best classifier is: \", grid.best_estimator_)\n",
    "print(\"The best score is: \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed: 16.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The best classifier is: ', LogisticRegression(C=46, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=21, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False))\n",
      "('The best score is: ', 0.98210570120682483)\n"
     ]
    }
   ],
   "source": [
    "# optimize the C in 45 to 55\n",
    "clf_lr= LogisticRegression(random_state = 21)\n",
    "parameters = {'solver' : ['newton-cg'],\n",
    "              'C':[i for i in range(45, 56)]}\n",
    "grid = GridSearchCV(clf_lr, parameters, scoring = 'accuracy', n_jobs = -1, verbose=True)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"The best classifier is: \", grid.best_estimator_)\n",
    "print(\"The best score is: \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed: 13.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The best classifier is: ', LogisticRegression(C=46, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=21, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False))\n",
      "('The best score is: ', 0.98210570120682483)\n"
     ]
    }
   ],
   "source": [
    "# optimize the C.\n",
    "clf_lr= LogisticRegression(random_state = 21)\n",
    "parameters = {'solver' : ['newton-cg'],\n",
    "              'C':[(i/10) for i in range(455, 466)]}\n",
    "grid = GridSearchCV(clf_lr, parameters, scoring = 'accuracy', n_jobs = -1, verbose=True)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"The best classifier is: \", grid.best_estimator_)\n",
    "print(\"The best score is: \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "** _After a series of optimizing best C we found with newton-cg as the scoring function and l2 as penalty is: 46_**\n",
    "\n",
    "Now lets fit the classifier and find out the accuracy we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for Logistic Regression is: 0.988025889968\n",
      "F1 Score for Logistic Regression is: 0.988019092014\n",
      "Runtime is 202.429314 seconds\n",
      "Log Loss Score is: 0.040566206566\n"
     ]
    }
   ],
   "source": [
    "clf_lr= LogisticRegression(penalty = 'l2', C = 46, solver= 'newton-cg', multi_class='ovr')\n",
    "strt = time.clock()\n",
    "clf_lr.fit(X_train, y_train)\n",
    "pred_lr = clf_lr.predict(X_test)\n",
    "end = time.clock()\n",
    "y_pred = clf_lr.predict_proba(X_test)\n",
    "print('Accuracy Score for Logistic Regression is: {}'.format(accuracy_score(y_test, pred_lr)))\n",
    "print('F1 Score for Logistic Regression is: {}'.format(f1_score(y_test, pred_lr, average = 'weighted')))\n",
    "print('Runtime is {} seconds'.format(end-start))\n",
    "print('Log Loss Score is: {}'.format(log_loss(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: Optimum Values:\n",
    "\n",
    "After multiple Grid Search we found the best parameters as:\n",
    "\n",
    "* Solver= newton-cg\n",
    "* C = 46\n",
    "\n",
    "The performance of our model is as follows:\n",
    "\n",
    "* Accuracy Score for Logistic Regression is: 0.988025889968\n",
    "* F1 Score for Logistic Regression is: 0.988019092014\n",
    "* Runtime is 202.429314 seconds\n",
    "* Log Loss Score is: 0.040566206566\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
